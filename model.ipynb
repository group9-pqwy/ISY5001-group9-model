{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "99GAmVtqKp1h"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.cluster import KMeans\n",
        "import joblib\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import Input, Embedding, Reshape, Concatenate, Dense, Dropout\n",
        "from keras.models import Model\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from scipy.sparse import vstack\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --- 数据加载和预处理 ---\n",
        "df = pd.read_csv(\"clean_data.csv\")\n",
        "# 数值特征分箱 (只保留 condition 和 mmr)\n",
        "# 数值特征分箱 (只保留 condition)\n",
        "numerical_features = ['condition']  # MMR 不再分箱\n",
        "for feature in numerical_features:\n",
        "    df[feature] = pd.qcut(df[feature], q=5, labels=False, duplicates='drop').astype(str)\n",
        "\n",
        "# 字符串特征处理\n",
        "string_cols = df.select_dtypes(include='object').columns\n",
        "df[string_cols] = df[string_cols].fillna(\"Unknown\")\n",
        "\n",
        "\n",
        "# price_odometer_scaler = StandardScaler()\n",
        "# df[['sellingprice', 'odometer']] = price_odometer_scaler.fit_transform(df[['sellingprice', 'odometer']])\n",
        "\n",
        "\n",
        "\n",
        "# --- 特征列表 ---\n",
        "features = ['make', 'model', 'trim', 'body', 'transmission', 'state', 'condition', 'color', 'interior', 'mmr']\n",
        "\n",
        "# --- 词嵌入 ---\n",
        "feature_combinations = df[features].apply(lambda row: row.values.astype(str).tolist(), axis=1).tolist()\n",
        "model_w2v = Word2Vec(feature_combinations, vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "# --- MMR 缩放 ---  (提前到这里)\n",
        "mmr_scaler = MinMaxScaler()\n",
        "df['mmr_scaled'] = mmr_scaler.fit_transform(df[['mmr']])\n",
        "\n",
        "# --- 构建包含 mmr_scaled 的特征向量 ---  (使用缩放后的 MMR)\n",
        "car_vectors_with_mmr = df.apply(\n",
        "    lambda car: np.concatenate([\n",
        "        np.mean(\n",
        "            [model_w2v.wv[feature] for feature in car[features].values.astype(str) if feature in model_w2v.wv and feature != 'mmr'] or [np.zeros(100)],\n",
        "            axis=0\n",
        "        ),\n",
        "        np.array([car['mmr_scaled']])  # 使用缩放后的 MMR\n",
        "    ]),\n",
        "    axis=1).tolist()\n",
        "\n",
        "\n",
        "# --- 重新训练 scaler --- (使用包含 MMR_scaled 的向量)\n",
        "scaler = StandardScaler().fit(car_vectors_with_mmr)\n",
        "car_vectors_with_mmr = scaler.transform(car_vectors_with_mmr)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cyFJw5LwBqFw"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- K-means 聚类 --- (使用缩放后的 car_vectors_with_mmr)\n",
        "n_clusters = 50\n",
        "kmeans = KMeans(n_clusters=n_clusters, random_state=42).fit(car_vectors_with_mmr)  # 使用 car_vectors_with_mmr\n",
        "df['cluster'] = kmeans.labels_\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# --- 基于内容的推荐 ---\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.layers import Dense\n",
        "def content_based_recommendation(user_input, all_car_vectors, top_n=5, min_price=-np.inf, max_price=np.inf, min_odo=-np.inf, max_odo=np.inf):\n",
        "    \"\"\"基于内容的推荐，根据用户输入的特征、价格和里程数范围，返回最相似的车辆。\"\"\"\n",
        "    user_input_df = pd.DataFrame([user_input])\n",
        "\n",
        "    # 过滤符合条件的车辆\n",
        "    filtered_df = df[\n",
        "        (df['sellingprice'] >= min_price) &\n",
        "        (df['sellingprice'] <= max_price) &\n",
        "        (df['odometer'] >= min_odo) &\n",
        "        (df['odometer'] <= max_odo)\n",
        "    ]\n",
        "\n",
        "    # 计算用户特征向量\n",
        "    user_vector = np.mean(\n",
        "        [model_w2v.wv[feature] if feature != 'mmr' else np.array([user_input['mmr']]) for feature in user_input_df[features].values.astype(str)[0] if (feature in model_w2v.wv or feature == 'mmr')], # 获取所有特征，包括MMR\n",
        "        axis=0 #计算均值\n",
        "    )\n",
        "    user_vector = np.concatenate([user_vector,np.array([user_input['mmr_scaled']])])\n",
        "    user_vector = scaler.transform([user_vector]) #scaler要用101维的\n",
        "\n",
        "    if len(filtered_df) == 0:\n",
        "        print(\"没有找到符合条件的车辆。\")\n",
        "        return pd.DataFrame(columns=df.columns)  # 返回空的 DataFrame\n",
        "\n",
        "    #  使用预先计算好的特征向量，避免重复计算\n",
        "    filtered_car_vectors = all_car_vectors[filtered_df.index]\n",
        "\n",
        "    similarities = cosine_similarity(user_vector, filtered_car_vectors)[0]\n",
        "    similar_car_indices = np.argsort(similarities)[::-1][:top_n]\n",
        "    return filtered_df.iloc[similar_car_indices]"
      ],
      "metadata": {
        "id": "XB5mRUZ59FUc"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def matrix_factorization_recommendation(user_ratings, initial_recommendations, df, car_vectors, scaler, model_w2v, n_clusters, kmeans, features):\n",
        "    user_id = 0  # 假设只有一个用户\n",
        "    user_car_array = np.array([])\n",
        "    ratings_df = pd.DataFrame({'userId': [user_id] * len(user_ratings),\n",
        "                                 'carId': initial_recommendations.index,\n",
        "                                 'rating': user_ratings})\n",
        "\n",
        "\n",
        "    try:\n",
        "        existing_ratings = pd.read_csv(\"ratings.csv\")\n",
        "    except FileNotFoundError:\n",
        "        existing_ratings = pd.DataFrame(columns=['userId', 'carId', 'rating'])\n",
        "\n",
        "    df_ratings = pd.concat([existing_ratings, ratings_df], ignore_index=True)\n",
        "\n",
        "    df_p = df_ratings.pivot_table(index='userId', columns='carId', values='rating')\n",
        "    mean_rating = df_ratings['rating'].mean()\n",
        "    df_ratings['rating'] = df_ratings['rating'].fillna(mean_rating)\n",
        "\n",
        "    df_title = df_ratings\n",
        "    user_ids = df_title[\"userId\"].unique().tolist()\n",
        "    user2user_encoded = {x: i for i, x in enumerate(user_ids)}\n",
        "    userencoded2user = {i: x for i, x in enumerate(user_ids)}\n",
        "    car_ids = df_title[\"carId\"].unique().tolist()\n",
        "    car2car_encoded = {x: i for i, x in enumerate(car_ids)}\n",
        "    car_encoded2car = {i: x for i, x in enumerate(car_ids)}\n",
        "    df_title[\"user\"] = df_title[\"userId\"].map(user2user_encoded)\n",
        "    df_title[\"car\"] = df_title[\"carId\"].map(car2car_encoded)\n",
        "\n",
        "    num_users = len(user2user_encoded)\n",
        "    num_cars = len(car_encoded2car)\n",
        "    df_title[\"rating\"] = df_title[\"rating\"].values.astype(np.float32)\n",
        "\n",
        "    min_rating = min(df_title[\"rating\"])\n",
        "    max_rating = max(df_title[\"rating\"])\n",
        "\n",
        "    df_title = df_title.sample(frac=1, random_state=42)\n",
        "    x = df_title[[\"user\", \"car\"]].values\n",
        "    y = df_title[\"rating\"].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values\n",
        "\n",
        "    train_indices = int(0.9 * df.shape[0])\n",
        "    x_train, x_val, y_train, y_val = (\n",
        "        x[:train_indices],\n",
        "        x[train_indices:],\n",
        "        y[:train_indices],\n",
        "        y[train_indices:],\n",
        "    )\n",
        "\n",
        "    embedding_size = 10\n",
        "\n",
        "    user_id_input = Input(shape=[1], name='user')\n",
        "    car_id_input = Input(shape=[1], name='car')\n",
        "\n",
        "    user_embedding = Embedding(output_dim=embedding_size,\n",
        "                                input_dim=num_users,\n",
        "                                embeddings_initializer=\"he_normal\",\n",
        "                                embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
        "                                name='user_embedding')(user_id_input)\n",
        "\n",
        "    car_embedding = Embedding(output_dim=embedding_size,\n",
        "                                input_dim=num_cars,\n",
        "                                embeddings_initializer=\"he_normal\",\n",
        "                                embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
        "                                name='car_embedding')(car_id_input)\n",
        "\n",
        "    user_vector = Reshape([embedding_size])(user_embedding)\n",
        "    car_vector = Reshape([embedding_size])(car_embedding)\n",
        "\n",
        "    concat = Concatenate()([user_vector, car_vector])\n",
        "    dense1 = Dense(64, kernel_regularizer=l2(0.01))(concat)\n",
        "    dense = Dropout(0.2)(dense1)\n",
        "    y = Dense(1, activation=\"sigmoid\")(dense)\n",
        "\n",
        "    model = Model(inputs=[user_id_input, car_id_input], outputs=y)\n",
        "    model.compile(loss='mse', optimizer='adam')\n",
        "\n",
        "    model.fit(x=[x_train[:, 0], x_train[:, 1]], y=y_train, batch_size=4, epochs=22, verbose=0)\n",
        "\n",
        "    cars_not_watched = df[~df[\"carId\"].isin(df_ratings[df_ratings['userId'] == user_id].carId.values)][\"carId\"]\n",
        "    cars_not_watched = list(set(cars_not_watched).intersection(set(car2car_encoded.keys())))\n",
        "    cars_not_watched = [[car2car_encoded.get(x)] for x in cars_not_watched]\n",
        "    user_encoder = user2user_encoded.get(user_id)\n",
        "    # 仅当 cars_not_watched 不为空时才构建 user_car_array\n",
        "    if cars_not_watched:\n",
        "        user_car_array = np.hstack(([[user_encoder]] * len(cars_not_watched), cars_not_watched))\n",
        "\n",
        "    # 检查 user_car_array 是否为空 (现在始终已赋值)\n",
        "    if user_car_array.size == 0:\n",
        "        print(\"没有未观看的车辆可供推荐。 使用默认值。\")\n",
        "        # 返回默认值\n",
        "        try: #尝试加载已保存的模型\n",
        "            model = keras.models.load_model('matrix_factorization_model.h5')\n",
        "            #如果模型文件存在，则返回加载的模型和其他默认值\n",
        "            return model, {}, {}, df_ratings['rating'].mean()\n",
        "        except:\n",
        "            #如果没有保存的模型，则创建一个新的模型并返回，以及其他默认值\n",
        "            # ...（构建模型的代码，与函数中其他部分相同）\n",
        "            return model, {}, {}, df_ratings['rating'].mean()\n",
        "\n",
        "    # 检查 user_car_array 的维度并进行 reshape\n",
        "    if user_car_array.ndim == 1:\n",
        "        user_car_array = user_car_array.reshape(1, -1)\n",
        "    elif user_car_array.shape[1] == 1:  # 检查是否只有一列\n",
        "        user_car_array = user_car_array.reshape(-1, 1)\n",
        "\n",
        "    # 根据 user_car_array 的形状构建模型输入\n",
        "    if user_car_array.shape[1] == 1:  # 只有一列，可能是只有 user_id\n",
        "        ratings = model.predict([user_car_array[:, 0]]).flatten() #这里也要修改\n",
        "    else: #有两列，user_id 和 car_id\n",
        "        ratings = model.predict([user_car_array[:, 0], user_car_array[:, 1]]).flatten()\n",
        "\n",
        "\n",
        "    top_ratings_indices = ratings.argsort()[-10:][::-1]\n",
        "    recommended_car_ids = [car_encoded2car.get(cars_not_watched[x][0]) for x in top_ratings_indices]\n",
        "\n",
        "    # 修改输出部分：\n",
        "    print(\"Showing recommendations for user: {}\".format(user_id))\n",
        "    print(\"=\" * 36)\n",
        "    print(\"-\" * 30)\n",
        "    print(\" Top 10 car recommendations\")\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    recommended_cars = df[df[\"carId\"].isin(recommended_car_ids)]\n",
        "\n",
        "    # 选择要打印的列，包括原始的数值列\n",
        "    recommended_cars = df[df[\"carId\"].isin(recommended_car_ids)]\n",
        "\n",
        "    columns_to_print = ['make', 'model', 'trim', 'body', 'transmission', 'state', 'color', 'interior'] + numerical_features  # 使用原始数值列名\n",
        "    print(recommended_cars[columns_to_print].to_string(index=False))\n",
        "    return model, user2user_encoded, car2car_encoded, df_ratings['rating'].mean()\n",
        "\n",
        "# def simulate_user_ratings(df, num_users=50, ratings_per_user=10):\n",
        "#     \"\"\"模拟用户评分数据。\"\"\"\n",
        "#     all_car_ids = df['carId'].unique()\n",
        "#     ratings = []\n",
        "\n",
        "#     for user_id in range(num_users):\n",
        "#         rated_car_ids = np.random.choice(all_car_ids, size=ratings_per_user, replace=True)\n",
        "#         for car_id in rated_car_ids:\n",
        "#             rating = np.random.randint(1, 6)\n",
        "#             ratings.append([user_id, car_id, rating])\n",
        "\n",
        "#     return pd.DataFrame(ratings, columns=['userId', 'carId', 'rating'])\n",
        "def simulate_user_ratings(df, car_vectors, num_users=50, ratings_per_user=10):\n",
        "    \"\"\"模拟用户评分数据，基于物品相似度进行预测，使用稀疏矩阵提高效率。\"\"\"\n",
        "    all_car_ids = df['carId'].unique()\n",
        "    num_cars = len(all_car_ids)\n",
        "\n",
        "    # 预先计算整个相似度矩阵 (稀疏矩阵)\n",
        "    similarity_matrix = cosine_similarity(car_vectors, dense_output=False)  # 直接生成稀疏矩阵\n",
        "\n",
        "    ratings = []\n",
        "    for user_id in range(num_users):\n",
        "        rated_car_ids = np.random.choice(all_car_ids, size=ratings_per_user, replace=False)\n",
        "        rated_car_indices = [np.where(all_car_ids == car_id)[0][0] for car_id in rated_car_ids] #简化索引查找\n",
        "        rated_car_ratings = np.random.randint(1, 6, size=ratings_per_user)\n",
        "\n",
        "\n",
        "        for car_index in range(num_cars):\n",
        "            if car_index in rated_car_indices:\n",
        "                continue  # 跳过已经评分的车辆\n",
        "\n",
        "            # 保持稀疏矩阵运算，避免转换为密集矩阵\n",
        "            similarity_scores = similarity_matrix[rated_car_indices, car_index].toarray().flatten()  # 这里仍然需要flatten\n",
        "            weighted_ratings = similarity_scores * rated_car_ratings\n",
        "\n",
        "            # 处理空相似度的情况\n",
        "            if np.sum(similarity_scores) != 0:\n",
        "                predicted_rating = np.sum(weighted_ratings) / np.sum(similarity_scores)\n",
        "            else:  # 如果没有相似车辆，则用平均值或其他策略\n",
        "                predicted_rating = np.mean(rated_car_ratings) if len(rated_car_ratings) > 0 else 3  # 默认值3\n",
        "\n",
        "\n",
        "            ratings.append([user_id, all_car_ids[car_index], predicted_rating])\n",
        "\n",
        "    return pd.DataFrame(ratings, columns=['userId', 'carId', 'rating'])\n",
        "\n",
        "\n",
        "# --- 获取用户评分 ---\n",
        "def get_user_ratings(recommendations):\n",
        "    \"\"\"模拟用户评分的函数，可以让用户为推荐的车辆打分\"\"\"\n",
        "    print(\"请为以下推荐车辆打分（1-5）：\")\n",
        "    user_ratings = []\n",
        "    for index, row in recommendations.iterrows():\n",
        "        # 注意：这里不再需要显示 'sellingprice' 和 'odometer' 的信息\n",
        "        rating = input(f\"{row['make']} {row['model']} {row['trim']} ({row['year']}): \")\n",
        "        user_ratings.append(int(rating))\n",
        "    return user_ratings\n"
      ],
      "metadata": {
        "id": "jGSER76UBmwp"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_rating(model, user_id, car_id, user2user_encoded, car2car_encoded, mean_rating):\n",
        "    \"\"\"使用矩阵分解模型预测用户对车辆的评分.\"\"\"\n",
        "    user_encoded = user2user_encoded.get(user_id)\n",
        "    car_encoded = car2car_encoded.get(car_id)\n",
        "    if user_encoded is not None and car_encoded is not None:\n",
        "        rating = model.predict([np.array([user_encoded]), np.array([car_encoded])])\n",
        "        return rating[0][0]\n",
        "    else:\n",
        "        return mean_rating  # 使用平均评分作为默认值\n",
        "\n",
        "def hybrid_recommendation(user_id, content_recs, matrix_model, user2user_encoded, car2car_encoded, mean_rating, top_n=10, car_vectors=car_vectors, scaler=scaler, features=features, user_input=user_input, model_w2v=model_w2v):  # 添加 car_vectors, scaler 等作为默认参数\n",
        "    \"\"\"结合基于内容的推荐和矩阵分解推荐。\"\"\"\n",
        "\n",
        "    # 使用正确的连接方式计算 content_score，并处理缺少 MMR_scaled 的情况\n",
        "    try:\n",
        "        user_vector = np.mean([model_w2v.wv[feature] if feature != 'mmr' else np.array([user_input['mmr']]) for feature in content_recs[features].iloc[0].values.astype(str) if (feature in model_w2v.wv or feature == 'mmr')], axis=0)\n",
        "        user_vector = np.concatenate([user_vector, np.array([user_input['mmr_scaled']])])\n",
        "        user_vector = scaler.transform([user_vector])\n",
        "\n",
        "        content_recs['content_score'] = content_recs.apply(\n",
        "            lambda row: cosine_similarity(user_vector, [np.concatenate([car_vectors[row.name], np.array([row['mmr_scaled']])])])[0][0] if 'mmr_scaled' in row else 0,  # 处理缺少 'mmr_scaled' 的情况\n",
        "            axis=1\n",
        "        )\n",
        "    except Exception as e:  # 捕获任何潜在错误\n",
        "        print(f\"计算 content_score 时出错: {e}\")\n",
        "        content_recs['content_score'] = 0  # 如果出现错误，设置默认值\n",
        "\n",
        "    # 为基于内容的推荐预测矩阵分解得分\n",
        "    content_recs['matrix_score'] = content_recs.apply(\n",
        "        lambda row: predict_rating(matrix_model, user_id, row.name, user2user_encoded, car2car_encoded, mean_rating),\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    content_recs['combined_score'] = 0.3 * content_recs['content_score'] + 0.7 * content_recs['matrix_score']\n",
        "\n",
        "    return content_recs.sort_values(by='combined_score', ascending=False).head(top_n)\n"
      ],
      "metadata": {
        "id": "LcFPrsNoQZPJ"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"df shape:\", df.shape)\n",
        "print(\"car_vectors shape:\", np.array(car_vectors).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lxz_sEflAjm3",
        "outputId": "d5986ff1-2988-4a14-fca9-eb4ef141bc4c"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "df shape: (550199, 20)\n",
            "car_vectors shape: (550199, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "user_input = {\n",
        "        'make': input(\"请输入品牌: \"),\n",
        "        'model': input(\"请输入型号: \"),\n",
        "        'trim': input(\"请输入版本: \"),\n",
        "        'body': input(\"请输入车身类型: \"),\n",
        "        'transmission': input(\"请输入变速箱类型: \"),\n",
        "        'state': input(\"请输入车辆所在州: \"),\n",
        "        'condition': input(\"请输入车况评分 (0-4): \"),\n",
        "        'color': input(\"请输入颜色: \"),\n",
        "        'interior': input(\"请输入内饰颜色: \"),\n",
        "        'mmr': float(input(\"请输入 MMR 评分: \")), # 获取 MMR 数值\n",
        "        'min_price': float(input(\"请输入最低价格: \")),\n",
        "        'max_price': float(input(\"请输入最高价格: \")),\n",
        "        'min_odo': float(input(\"请输入最低里程数: \")),\n",
        "        'max_odo': float(input(\"请输入最高里程数: \"))\n",
        "    }\n",
        "# 缩放用户输入的 MMR\n",
        "user_input['mmr_scaled'] = mmr_scaler.transform([[user_input['mmr']]])[0][0] # 缩放用户输入的MMR\n",
        "\n",
        "df['carId'] = df.index\n",
        "# 尝试读取用户评分数据\n",
        "\n",
        "# --- 读取用户评分数据 ---\n",
        "try:\n",
        "    existing_ratings = pd.read_csv(\"/content/ratings (1).csv\")  # 或你的 ratings.csv 文件路径\n",
        "except FileNotFoundError:\n",
        "    existing_ratings = pd.DataFrame(columns=['userId', 'carId', 'rating'])\n",
        "\n",
        "\n",
        "# ---  模拟更多用户评分  ---\n",
        "# --- 模拟更多用户评分 ---\n",
        "# if existing_ratings.empty or len(existing_ratings) < 50:\n",
        "#     simulated_ratings = simulate_user_ratings(df, car_vectors, num_users=50, ratings_per_user=10)  # 生成更多模拟数据\n",
        "#     existing_ratings = pd.concat([existing_ratings, simulated_ratings], ignore_index=True)\n",
        "#     existing_ratings.to_csv(\"ratings.csv\", index=False)\n",
        "#     print(\"已模拟并保存用户评分数据到 ratings.csv\")\n",
        "\n",
        "\n",
        "\n",
        "# ---  核心推荐逻辑 ---\n",
        "if existing_ratings.empty or len(existing_ratings) < 10:\n",
        "    print(\"使用基于内容的推荐...\")\n",
        "    initial_recs = content_based_recommendation(user_input, all_car_vectors, top_n=5, # 传入 all_car_vectors\n",
        "                                            min_price=user_input['min_price'],\n",
        "                                            max_price=user_input['max_price'],\n",
        "                                            min_odo=user_input['min_odo'],\n",
        "                                            max_odo=user_input['max_odo'])\n",
        "\n",
        "    if initial_recs is not None and not initial_recs.empty:\n",
        "        if {'model', 'trim'}.issubset(initial_recs.columns):\n",
        "            print(\"基于您输入的特征，我们推荐以下车辆：\")\n",
        "            print(initial_recs[['year', 'make', 'model', 'trim']])\n",
        "            user_ratings = get_user_ratings(initial_recs)\n",
        "\n",
        "            # 保存用户评分 (更新 existing_ratings)\n",
        "            user_id = existing_ratings['userId'].max() + 1 if not existing_ratings.empty else 0\n",
        "            ratings_df = pd.DataFrame({'userId': [user_id] * len(user_ratings),\n",
        "                                        'carId': initial_recs.index,\n",
        "                                        'rating': user_ratings})\n",
        "            existing_ratings = pd.concat([existing_ratings, ratings_df], ignore_index=True)\n",
        "            existing_ratings.to_csv(\"ratings.csv\", index=False)\n",
        "\n",
        "            print(\"\\n根据您的评分，我们更新了推荐：\")\n",
        "            # 调用矩阵分解函数并保存模型\n",
        "            matrix_model = matrix_factorization_recommendation(user_ratings, initial_recs, df.copy(), car_vectors, scaler, model_w2v, n_clusters, kmeans, features)\n",
        "            matrix_model.save('matrix_factorization_model.h5')\n",
        "            print(\"矩阵分解模型已保存为 matrix_factorization_model.h5\")\n",
        "        else:\n",
        "            print(\"推荐结果中不包含 'model' 或 'trim' 列。\")\n",
        "    else:\n",
        "        print(\"找不到符合您输入特征的车辆。\")\n",
        "\n",
        "\n",
        "else:  # 使用混合推荐\n",
        "    print(\"使用混合推荐...\")\n",
        "    initial_recs = content_based_recommendation(user_input, all_car_vectors)  # 传入 all_car_vectors\n",
        "\n",
        "    if initial_recs is not None and not initial_recs.empty:\n",
        "        if {'model', 'trim'}.issubset(initial_recs.columns):\n",
        "            print(\"基于您输入的特征，我们推荐以下车辆：\")\n",
        "            print(initial_recs[['year', 'make', 'model', 'trim']])\n",
        "            user_ratings = get_user_ratings(initial_recs)\n",
        "\n",
        "            # 调用矩阵分解函数并处理可能的 None 返回值\n",
        "            result = matrix_factorization_recommendation(user_ratings, initial_recs, df.copy(), car_vectors, scaler, model_w2v, n_clusters, kmeans, features)\n",
        "\n",
        "            if result: #检查返回值是否为空\n",
        "                matrix_model, user2user_encoded, car2car_encoded, mean_rating = result\n",
        "                matrix_model.save('matrix_factorization_model.h5')\n",
        "                print(\"矩阵分解模型已保存为 matrix_factorization_model.h5\")\n",
        "\n",
        "                user_id = existing_ratings['userId'].max() if not existing_ratings.empty else 0 # 使用最大user_id或0\n",
        "                final_recommendations = hybrid_recommendation(\n",
        "                    user_id,\n",
        "                    initial_recs.copy(),\n",
        "                    matrix_model,\n",
        "                    user2user_encoded,\n",
        "                    car2car_encoded,\n",
        "                    mean_rating,\n",
        "                )\n",
        "                print(\"\\n最终混合推荐结果：\")\n",
        "                print(final_recommendations[['year', 'make', 'model', 'trim', 'combined_score']])\n",
        "\n",
        "            else:\n",
        "                print(\"矩阵分解推荐失败，可能没有足够的未观看车辆。\") #处理返回值为空的情况\n",
        "\n",
        "\n",
        "        else:\n",
        "            print(\"推荐结果中不包含 'model' 或 'trim' 列。\")\n",
        "    else:\n",
        "        print(\"找不到符合您输入特征的车辆。\")\n",
        "\n",
        "# 保存模型和scaler\n",
        "joblib.dump(model_w2v, 'word2vec_model.pkl')\n",
        "joblib.dump(scaler, 'scaler.pkl')\n",
        "joblib.dump(kmeans, 'kmeans_model.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPUr4JZzBohz",
        "outputId": "8eeecc3b-e3a3-4c56-f1a3-b1d2b438fc1c"
      },
      "execution_count": 46,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "请输入品牌: BMW\n",
            "请输入型号: camry\n",
            "请输入版本: LE\n",
            "请输入车身类型: Unknown\n",
            "请输入变速箱类型: Automatic\n",
            "请输入车辆所在州: ca\n",
            "请输入车况评分 (0-4): 4\n",
            "请输入颜色: black\n",
            "请输入内饰颜色: gray\n",
            "请输入 MMR 评分: 30000\n",
            "请输入最低价格: 10000\n",
            "请输入最高价格: 40000\n",
            "请输入最低里程数: 0\n",
            "请输入最高里程数: 50000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "使用混合推荐...\n",
            "基于您输入的特征，我们推荐以下车辆：\n",
            "        year make model  trim\n",
            "466005  2007  BMW    M6  Base\n",
            "537582  2010  BMW    M6  Base\n",
            "460532  2012  BMW  X5 M  Base\n",
            "501928  2007  BMW  Z4 M  Base\n",
            "467571  2011  BMW  X5 M  Base\n",
            "请为以下推荐车辆打分（1-5）：\n",
            "BMW M6 Base (2007): 4\n",
            "BMW M6 Base (2010): 3\n",
            "BMW X5 M Base (2012): 5\n",
            "BMW Z4 M Base (2007): 4\n",
            "BMW X5 M Base (2011): 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-37-f9a69b23e4a6>:18: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df_ratings['rating'] = df_ratings['rating'].fillna(mean_rating)\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "没有未观看的车辆可供推荐。 使用默认值。\n",
            "矩阵分解模型已保存为 matrix_factorization_model.h5\n",
            "\n",
            "最终混合推荐结果：\n",
            "        year make model  trim  combined_score\n",
            "466005  2007  BMW    M6  Base        2.893379\n",
            "537582  2010  BMW    M6  Base        2.891422\n",
            "467571  2011  BMW  X5 M  Base        2.868679\n",
            "460532  2012  BMW  X5 M  Base        2.867665\n",
            "501928  2007  BMW  Z4 M  Base        2.856661\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['kmeans_model.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}